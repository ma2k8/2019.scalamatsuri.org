---
name: Chetan Khatri
title: "従来のリレーショナルデータウェアハウスから Spark と Scala のパワーを使った分散データウェアハウスへ"
length: 40
audience: Beginner
language: English
twitter: khatri_chetan
github: chetkhatri
icon: https://s.gravatar.com/avatar/4c0ea55b34c2b6f50c32024b750c7161?s=80
organization: Accionlabs Inc.
tags:
  - Big Data / Fast Data
  - Functional Programming
  - Best Practices
suggestions:
  - 1. Scala を用いた関数型プログラミングの初歩か、 Java を理解してる人
  - 2. Java もしくは Scala で並行プログラミングかマルチスレッドを理解している人
  - 3. 分散データ処理に興味があって、データをスケールさせる最適化に興味があるひと
contributes:
  - Apache Spark
  - Apache HBase
  - Apache MXNet
speaker_experience:
  - TransmogrifAI - Automate Machine Learning Workflow with the power of Scala and Spark at massive scale. - Scala.IO 2018 Lyon, France.
  - Scaling 30 TB's of Data lake with Apache HBase and Scala DSL at Production. - HBaseConAsia 2018, Beijing - China.
  - Scaling TB's of data with Apache Spark and Scala DSL at Production - HKOSCon 2018
---
今でも多くの大企業は従来のリレーショナルなデータウェアハウスに頼っています。企業の大量の取引データはリレーショナルなデータウェアハウスへと永続化されています。解析の目的というだけでなく、データそのものの爆発的な増加により、ビジネスのための解析データの高可用性と高速なデータ処理の両方が求められる時代がやってきました。企業の多くが「データプラットフォームのリエンジニアリング」を検討しています。

この文脈において Scala そして Apache Spark はモダンな分散解析基盤として非常に人気を博しています。
